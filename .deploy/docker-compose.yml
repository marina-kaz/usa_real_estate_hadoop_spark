version: '3.8'

services:
  spark-yarn-master:
    container_name: da-spark-yarn-master
    build:
      context: .
    image: da-spark-yarn-image
    entrypoint: ['./entrypoint.sh', 'master']
    volumes:
      - ./spark_data:/opt/spark/data
      - ./spark_apps:/opt/spark/apps
    env_file:
      - .env.spark
    ports:
      - '8080:8080'
      - '9870:9870'
      - '7077:7077'
      - '8088:8088'


  spark-yarn-worker:
    image: da-spark-yarn-image
    entrypoint: ['./entrypoint.sh', 'worker']
    depends_on:
      - spark-yarn-master
    env_file:
      - .env.spark
    volumes:
      - ./hadoop_data:/opt/spark/data
      - ./client:/opt/spark/apps


  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    ports:
      - 9864:9864
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - .env.spark
    networks:
      - hadoop-network
    platform: linux/amd64
    deploy:
      resources:
        limits:
          memory: 4G

  yarn-history-server:
    container_name: da-spark-yarn-history
    image: da-spark-yarn-image
    entrypoint: ['./entrypoint.sh', 'history']
    depends_on:
      - spark-yarn-master
    env_file:
      - .env.spark
    ports:
      - '18080:18080'

networks:
  default:
    name: hadoop-network
